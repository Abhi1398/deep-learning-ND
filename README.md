# deep-learning-ND
This repository was created for the [Deep Learning Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101) at [Udacity](https://www.udacity.com/). The original tutorial and project notebooks for this course can be found at the [deep-learning-v2-pytorch](https://github.com/udacity/deep-learning-v2-pytorch) repository.

## Project 1: Predicting Bike-Sharing Patterns

[Predicting Bike-Sharing Patterns Project](project-bikesharing)<br/>

In this project, I build a neural network from scratch to carry out a prediction problem on a real dataset! By building a neural network from the ground up, I have a much better understanding of gradient descent, backpropagation, and other concepts that are important to know before moving on to higher level tools such as PyTorch. The data comes from the [UCI Machine Learning Database](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).


## Project 2: Dog-Breed Classifier

[Dog-Breed Classifier Project](project-dog-classification)<br/>

In this project, I build a pipeline to process real-world, user-supplied images. Given an image of a dog, my algorithm will identify an estimate of the canineâ€™s breed by using state-of-the-art CNN models for classification. If supplied an image of a human face, the code will identify the resembling dog breed.

## Project 3: TV Script Generation
[TV Script Generation Project](project-tv-script-generation)<br/>

In this project, I generate my own Seinfeld TV scripts using a recurrent neural network (RNN). The dataset used to train the network consists of scripts from 9 Seinfeld seasons. After training on the dataset, the RNN can create a new, "fake" TV script.

### Generated script

A script generated by my RNN

>kramer: listen jerry, i'm sorry. i just don't know what it is.
>
>jerry: what?
>
>george: you don't know? how could i go out with her?
>
>jerry: no.
>
>helen: what are you doing?
>
>jerry: what about that?
>
>george:(to the phone) hey. i don't know what you're saying.
>
>jerry: i don't think so.
>
>george: yeah...
>
>jerry: oh, that's right.
>
>george: yeah, right. i was wondering if you could do your own business. it's not that.
>
>jerry: i don't have you.
>
>kramer: no, no, don't you?... no, i want you to be there and i can have the car.
>
>george: oh, oh, i can't believe this isn't a good time.
>
>jerry: what is this?
>
>george:(to the man) oh, i gotta go!
>
>jerry: i got a lot of people in the car.
>
>kramer: yeah.
>
>jerry: hey.
>
>kramer: yeah, you got it, i just want to be a good one.
>
>kramer: yeah, yeah.(she looks at her watch) oh, you know, you got my keys, you were right on the top.
>
>kramer:(to kramer) hey!
>
>kramer: hey, hey jerry.
>
>elaine:(to kramer) hey you guys, what are you doing here?
>
>kramer: i didn't know i said" hello"
>
>jerry:"(to kramer) so, what do you have to say?
>
>jerry: i can't.
>
>george: i just think i'm gonna go to the bathroom and get the rest of my life. i have to do this.
>
>jerry: what are you talking about?
>
>george: why did you get that?
>
>jerry: well, it's like an accident.
>
>jerry: what did you say?
>
>george:(laughing) you got that

## Project 4: Face Generation
[Face Generation Project](project-face-generation)<br/>

In this project, I define and train deep convolutional generative adversarial networks (DCGAN) on a dataset of faces. The goal is to get a generator network to generate new images of faces that look as realistic as possible. The [CelebFaces Attributes Dataset (CelebA)](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) was used to train the adversarial networks.

## Exercises
[autoencoder](autoencoder)<br/>
[batch-norm](batch-norm)<br/>
[convolutional-neural-networks](convolutional-neural-networks)<br/>
[dcgan-svhn](dcgan-svhn)<br/>
[gan-mnist](gan-mnist)<br/>
[intro-neural-networks](intro-neural-networks)<br/>
[intro-to-pytorch](intro-to-pytorch)<br/>
[recurrent-neural-networks](recurrent-neural-networks)<br/>
[sentiment-analysis-network](sentiment-analysis-network)<br/>
[sentiment-rnn](sentiment-rnn)<br/>
[style-transfer](style-transfer)<br/>
[transfer-learning](transfer-learning)<br/>
[weight-initialization](weight-initialization)<br/>
[word2vec-embeddings](word2vec-embeddings)
